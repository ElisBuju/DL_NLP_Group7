{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c082cae5-6267-4834-a90b-e29e6f3a1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/micromamba/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/micromamba/lib/python3.11/site-packages (1.13.2)\n",
      "Requirement already satisfied: faiss-gpu-cu12 in /opt/micromamba/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/micromamba/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/micromamba/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/micromamba/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/micromamba/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/micromamba/lib/python3.11/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/micromamba/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pyarrow==14.0.1 in /opt/micromamba/lib/python3.11/site-packages (14.0.1)\n",
      "Requirement already satisfied: datasets==2.14.6 in /opt/micromamba/lib/python3.11/site-packages (2.14.6)\n",
      "Requirement already satisfied: transformers==4.35.2 in /opt/micromamba/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: accelerate==0.24.1 in /opt/micromamba/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/micromamba/lib/python3.11/site-packages (from pyarrow==14.0.1) (1.26.4)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/micromamba/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (3.12.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (0.35.0)\n",
      "Requirement already satisfied: packaging in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/micromamba/lib/python3.11/site-packages (from datasets==2.14.6) (6.0.2)\n",
      "Requirement already satisfied: filelock in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.35.2) (3.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.35.2) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.35.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/micromamba/lib/python3.11/site-packages (from transformers==4.35.2) (0.6.2)\n",
      "Requirement already satisfied: psutil in /opt/micromamba/lib/python3.11/site-packages (from accelerate==0.24.1) (6.1.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/micromamba/lib/python3.11/site-packages (from accelerate==0.24.1) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/micromamba/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/micromamba/lib/python3.11/site-packages (from aiohttp->datasets==2.14.6) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/micromamba/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.14.6) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/micromamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.14.6) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.14.6) (2025.8.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/micromamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.24.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/micromamba/lib/python3.11/site-packages (from triton==3.4.0->torch>=1.10.0->accelerate==0.24.1) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/micromamba/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.24.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/micromamba/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate==0.24.1) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/micromamba/lib/python3.11/site-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/micromamba/lib/python3.11/site-packages (from pandas->datasets==2.14.6) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/micromamba/lib/python3.11/site-packages (from pandas->datasets==2.14.6) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/micromamba/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch faiss-cpu faiss-gpu-cu12 tqdm numpy==1.26.4\n",
    "\n",
    "!pip install pyarrow==14.0.1 datasets==2.14.6 transformers==4.35.2 accelerate==0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16857394-90da-41b5-892c-5c67888890f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/micromamba/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    RagTokenizer,\n",
    "    RagRetriever,\n",
    "    RagSequenceForGeneration,\n",
    "    RagTokenForGeneration\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {device}\")\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabab9f3-3a3f-4d56-b6ba-e80a6ed423b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def calculate_em(predictions, references):\n",
    "    total_em = 0\n",
    "    for pred, refs in zip(predictions, references):\n",
    "        if any(exact_match_score(pred, gt) for gt in refs):\n",
    "            total_em += 1\n",
    "    return 100 * (total_em / len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7be2ff-f99f-4dc6-ba13-1e357febd4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalRAGModelManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        rag_type,        \n",
    "        n_docs=5,\n",
    "        index_name=\"exact\",\n",
    "    ):\n",
    "        print(f\"Initializing RAG Manager...\")\n",
    "        self.tokenizer = RagTokenizer.from_pretrained(model_name)\n",
    "        self.retriever = RagRetriever.from_pretrained(model_name, index_name=index_name, use_dummy_dataset=False)\n",
    "\n",
    "        print(f\"[DEBUG] Loading Model from {model_name}...\")\n",
    "        ModelClass = RagTokenForGeneration if rag_type == \"token\" else RagSequenceForGeneration\n",
    "        self.model = ModelClass.from_pretrained(model_name, retriever=self.retriever).to(device)\n",
    "\n",
    "        self.model.config.n_docs = n_docs\n",
    "        self.model.eval()\n",
    "        print(\"[DEBUG] Model loaded successfully!\")\n",
    "\n",
    "    def set_n_docs(self, n_docs: int):\n",
    "        self.n_docs = n_docs\n",
    "        self.model.config.n_docs = n_docs\n",
    "        if hasattr(self.retriever, \"n_docs\"):\n",
    "            self.retriever.n_docs = n_docs\n",
    "        if hasattr(self.retriever, \"config\"):\n",
    "            self.retriever.config.n_docs = n_docs\n",
    "\n",
    "    def generate_answers(self, questions, batch_size=4):\n",
    "        all_answers = []\n",
    "        for i in tqdm(range(0, len(questions), batch_size), desc=f\"Generating (k={self.n_docs})\"):\n",
    "            batch_questions = questions[i: i + batch_size]\n",
    "            inputs = self.tokenizer(\n",
    "                batch_questions,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True\n",
    "            ).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                generated_ids = self.model.generate(\n",
    "                    input_ids=inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    n_docs=self.model.config.n_docs,\n",
    "                    num_beams=1,\n",
    "                    max_new_tokens=16,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "            all_answers.extend(self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True))\n",
    "        return all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8e9f06-7035-48f5-aaf8-e063a0edcc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WebQuestions Test Set...\n",
      "Loaded 2032 test samples from WebQuestions.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_TOKEN_CHECKPOINT = \"WQ_models/facebook_rag-token-nq__token__wq_ft__nDocs10__20260117_163413\" \n",
    "PATH_TO_SEQUENCE_CHECKPOINT = \"WQ_models/facebook_rag-sequence-nq__sequence__wq_ft__nDocs10__20260118_124326\"\n",
    "\n",
    "K_VALUES = [3, 5, 7, 10, 20, 30]\n",
    "NUM_SAMPLES = None\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Load data\n",
    "print(\"Loading WebQuestions Test Set...\")\n",
    "dataset = load_dataset(\"stanfordnlp/web_questions\", split=\"test\")\n",
    "\n",
    "questions = [row['question'] for row in dataset]\n",
    "answers = [row['answers'] for row in dataset]\n",
    "\n",
    "print(f\"Loaded {len(questions)} test samples from WebQuestions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e32f1c4-c188-404a-a39f-1297d310af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fine-Tuned RAG-Token ===\n",
      "Initializing RAG Manager...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/datasets_modules/datasets/wiki_dpr/66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c (last modified on Thu Jan 15 21:07:41 2026) since it couldn't be found locally at wiki_dpr., or remotely on the Hugging Face Hub.\n",
      "/opt/micromamba/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/datasets_modules/datasets/wiki_dpr/66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c (last modified on Thu Jan 15 21:07:41 2026) since it couldn't be found locally at wiki_dpr., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading Model from WQ_models/facebook_rag-token-nq__token__wq_ft__nDocs10__20260117_163413...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/micromamba/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Model loaded successfully!\n",
      "\n",
      "Processing k=3 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=3):   0%|          | 0/254 [00:00<?, ?it/s]/opt/micromamba/lib/python3.11/site-packages/transformers/generation/utils.py:2465: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
      "  warnings.warn(\n",
      "Generating (k=3): 100%|██████████| 254/254 [07:00<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=3): 31.74% (Time: 420.1s)\n",
      "\n",
      "Processing k=5 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=5): 100%|██████████| 254/254 [12:34<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=5): 32.04% (Time: 754.9s)\n",
      "\n",
      "Processing k=7 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=7): 100%|██████████| 254/254 [17:28<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=7): 32.53% (Time: 1048.2s)\n",
      "\n",
      "Processing k=10 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=10): 100%|██████████| 254/254 [22:11<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=10): 32.63% (Time: 1331.8s)\n",
      "\n",
      "Processing k=20 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=20): 100%|██████████| 254/254 [43:37<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=20): 32.68% (Time: 2617.2s)\n",
      "\n",
      "Processing k=30 for RAG-Token...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=30): 100%|██████████| 254/254 [1:06:02<00:00, 15.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=30): 32.82% (Time: 3962.7s)\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"rag-token\": {\"scores\": [], \"k\": K_VALUES},\n",
    "    \"rag-sequence\": {\"scores\": [], \"k\": K_VALUES}\n",
    "}\n",
    "\n",
    "# Evaluate Fine-Tuned RAG-TOKEN\n",
    "if PATH_TO_TOKEN_CHECKPOINT:\n",
    "    print(f\"\\n=== Evaluating Fine-Tuned RAG-Token ===\")\n",
    "    rag_token_mgr = LocalRAGModelManager(\n",
    "        model_name=PATH_TO_TOKEN_CHECKPOINT,\n",
    "        rag_type=\"token\"\n",
    "    )\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        print(f\"\\nProcessing k={k} for RAG-Token...\")\n",
    "        rag_token_mgr.set_n_docs(k)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        predictions = rag_token_mgr.generate_answers(questions, batch_size=BATCH_SIZE)\n",
    "        score = calculate_em(predictions, answers)\n",
    "        \n",
    "        results[\"rag-token\"][\"scores\"].append(score)\n",
    "        with open(\"benchmark_wq_k_results.json\", \"w\") as f:\n",
    "            json.dump(results, f)\n",
    "        print(f\"WQ Score (k={k}): {score:.2f}% (Time: {time.time()-start_time:.1f}s)\")\n",
    "\n",
    "    # Clean up GPU memory\n",
    "    del rag_token_mgr\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipping Token Model (No path provided)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5281ff-f858-4930-b02c-49f0209d118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Fine-Tuned RAG-Sequence ===\n",
      "Initializing RAG Manager...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/datasets_modules/datasets/wiki_dpr/66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c (last modified on Thu Jan 15 21:07:41 2026) since it couldn't be found locally at wiki_dpr., or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /home/jovyan/.cache/huggingface/modules/datasets_modules/datasets/wiki_dpr/66fd9b80f51375c02cd9010050e781ed3e8f759e868f690c31b2686a7a0eeb5c (last modified on Thu Jan 15 21:07:41 2026) since it couldn't be found locally at wiki_dpr., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loading Model from WQ_models/facebook_rag-sequence-nq__sequence__wq_ft__nDocs10__20260118_124326...\n",
      "[DEBUG] Model loaded successfully!\n",
      "\n",
      "Processing k=3 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=3):   0%|          | 0/254 [00:00<?, ?it/s]/opt/micromamba/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Generating (k=3): 100%|██████████| 254/254 [14:21<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=3): 33.56% (Time: 861.7s)\n",
      "\n",
      "Processing k=5 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=5): 100%|██████████| 254/254 [27:44<00:00,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=5): 35.09% (Time: 1664.4s)\n",
      "\n",
      "Processing k=7 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=7): 100%|██████████| 254/254 [45:03<00:00, 10.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=7): 36.37% (Time: 2703.7s)\n",
      "\n",
      "Processing k=10 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=10): 100%|██████████| 254/254 [1:15:39<00:00, 17.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=10): 37.01% (Time: 4539.3s)\n",
      "\n",
      "Processing k=20 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=20): 100%|██████████| 254/254 [3:34:10<00:00, 50.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ Score (k=20): 37.45% (Time: 12850.4s)\n",
      "\n",
      "Processing k=30 for RAG-Sequence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating (k=30):   0%|          | 0/254 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.54 GiB. GPU 0 has a total capacity of 14.57 GiB of which 3.14 GiB is free. Process 2578282 has 11.43 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m rag_seq_mgr.set_n_docs(k)\n\u001B[32m     13\u001B[39m start_time = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m predictions = \u001B[43mrag_seq_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_answers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m score = calculate_em(predictions, answers)\n\u001B[32m     17\u001B[39m results[\u001B[33m\"\u001B[39m\u001B[33mrag-sequence\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mscores\u001B[39m\u001B[33m\"\u001B[39m].append(score)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 41\u001B[39m, in \u001B[36mLocalRAGModelManager.generate_answers\u001B[39m\u001B[34m(self, questions, batch_size)\u001B[39m\n\u001B[32m     33\u001B[39m     inputs = \u001B[38;5;28mself\u001B[39m.tokenizer(\n\u001B[32m     34\u001B[39m         batch_questions,\n\u001B[32m     35\u001B[39m         return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     36\u001B[39m         padding=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     37\u001B[39m         truncation=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     38\u001B[39m     ).to(device)\n\u001B[32m     40\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m         generated_ids = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m            \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mattention_mask\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_docs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mn_docs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnum_beams\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m16\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m            \u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     48\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m     all_answers.extend(\u001B[38;5;28mself\u001B[39m.tokenizer.batch_decode(generated_ids, skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m all_answers\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/rag/modeling_rag.py:1020\u001B[39m, in \u001B[36mRagSequenceForGeneration.generate\u001B[39m\u001B[34m(self, input_ids, attention_mask, context_input_ids, context_attention_mask, doc_scores, do_deduplication, num_return_sequences, num_beams, n_docs, **model_kwargs)\u001B[39m\n\u001B[32m   1018\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1019\u001B[39m     new_input_ids = input_ids[index : index + \u001B[32m1\u001B[39m].repeat(num_candidates, \u001B[32m1\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1020\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_input_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_sequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude_bos_score\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   1021\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# input_ids is None, need context_input_ids/mask and doc_scores\u001B[39;00m\n\u001B[32m   1022\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m context_attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, (\n\u001B[32m   1023\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMake sure that `context_attention_mask` are passed, if no `input_ids` is set. Alternatively, you\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1024\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m can set a retriever using the `set_retriever(...)` function.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1025\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/rag/modeling_rag.py:844\u001B[39m, in \u001B[36mRagSequenceForGeneration.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, past_key_values, context_input_ids, context_attention_mask, doc_scores, use_cache, output_attentions, output_hidden_states, output_retrieved, exclude_bos_score, reduce_loss, labels, n_docs, **kwargs)\u001B[39m\n\u001B[32m    841\u001B[39m         decoder_input_ids = labels\n\u001B[32m    842\u001B[39m     use_cache = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m844\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrag\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    845\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    846\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    847\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    848\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    849\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    850\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontext_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcontext_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    851\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontext_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcontext_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    852\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdoc_scores\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdoc_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    853\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    854\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    855\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    856\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    857\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_retrieved\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_retrieved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    858\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_docs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_docs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    859\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    861\u001B[39m loss = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    862\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/rag/modeling_rag.py:680\u001B[39m, in \u001B[36mRagModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, past_key_values, doc_scores, context_input_ids, context_attention_mask, use_cache, output_attentions, output_hidden_states, output_retrieved, n_docs)\u001B[39m\n\u001B[32m    677\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m decoder_attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    678\u001B[39m     decoder_attention_mask = decoder_attention_mask.repeat_interleave(n_docs, dim=\u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m680\u001B[39m gen_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    681\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcontext_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    682\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcontext_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    683\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    684\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    685\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    686\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    687\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    688\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    689\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    690\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    692\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_to_retrieve:\n\u001B[32m    693\u001B[39m     question_encoder_last_hidden_state = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1577\u001B[39m, in \u001B[36mBartForConditionalGeneration.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1572\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m decoder_input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m decoder_inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1573\u001B[39m         decoder_input_ids = shift_tokens_right(\n\u001B[32m   1574\u001B[39m             labels, \u001B[38;5;28mself\u001B[39m.config.pad_token_id, \u001B[38;5;28mself\u001B[39m.config.decoder_start_token_id\n\u001B[32m   1575\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m1577\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1578\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1579\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1580\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1581\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1582\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1583\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1584\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1585\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attn_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1586\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1587\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1588\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoder_inputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1589\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1590\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1591\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1592\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1593\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1595\u001B[39m lm_logits = \u001B[38;5;28mself\u001B[39m.lm_head(outputs[\u001B[32m0\u001B[39m])\n\u001B[32m   1596\u001B[39m lm_logits = lm_logits + \u001B[38;5;28mself\u001B[39m.final_logits_bias.to(lm_logits.device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1445\u001B[39m, in \u001B[36mBartModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1442\u001B[39m return_dict = return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.use_return_dict\n\u001B[32m   1444\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m encoder_outputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1445\u001B[39m     encoder_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1446\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1447\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1448\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1449\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1450\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1451\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1452\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1453\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1454\u001B[39m \u001B[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001B[39;00m\n\u001B[32m   1455\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(encoder_outputs, BaseModelOutput):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1074\u001B[39m, in \u001B[36mBartEncoder.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m   1066\u001B[39m         layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m   1067\u001B[39m             encoder_layer.\u001B[34m__call__\u001B[39m,\n\u001B[32m   1068\u001B[39m             hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1071\u001B[39m             output_attentions,\n\u001B[32m   1072\u001B[39m         )\n\u001B[32m   1073\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1074\u001B[39m         layer_outputs = \u001B[43mencoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1075\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1076\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1077\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1078\u001B[39m \u001B[43m            \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1079\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1081\u001B[39m     hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1083\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:537\u001B[39m, in \u001B[36mBartEncoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    525\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    526\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m    527\u001B[39m \u001B[33;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    534\u001B[39m \u001B[33;03m        returned tensors for more detail.\u001B[39;00m\n\u001B[32m    535\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    536\u001B[39m residual = hidden_states\n\u001B[32m--> \u001B[39m\u001B[32m537\u001B[39m hidden_states, attn_weights, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    539\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    540\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    541\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    542\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    543\u001B[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001B[38;5;28mself\u001B[39m.dropout, training=\u001B[38;5;28mself\u001B[39m.training)\n\u001B[32m    544\u001B[39m hidden_states = residual + hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/micromamba/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:231\u001B[39m, in \u001B[36mBartAttention.forward\u001B[39m\u001B[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001B[39m\n\u001B[32m    228\u001B[39m value_states = value_states.reshape(*proj_shape)\n\u001B[32m    230\u001B[39m src_len = key_states.size(\u001B[32m1\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m attn_weights = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    233\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attn_weights.size() != (bsz * \u001B[38;5;28mself\u001B[39m.num_heads, tgt_len, src_len):\n\u001B[32m    234\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    235\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAttention weights should be of size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(bsz\u001B[38;5;250m \u001B[39m*\u001B[38;5;250m \u001B[39m\u001B[38;5;28mself\u001B[39m.num_heads,\u001B[38;5;250m \u001B[39mtgt_len,\u001B[38;5;250m \u001B[39msrc_len)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, but is\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    236\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattn_weights.size()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    237\u001B[39m     )\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 3.54 GiB. GPU 0 has a total capacity of 14.57 GiB of which 3.14 GiB is free. Process 2578282 has 11.43 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Evaluate Fine-Tuned RAG-SEQUENCE\n",
    "if PATH_TO_SEQUENCE_CHECKPOINT:\n",
    "    print(f\"\\n=== Evaluating Fine-Tuned RAG-Sequence ===\")\n",
    "    rag_seq_mgr = LocalRAGModelManager(\n",
    "        model_name=PATH_TO_SEQUENCE_CHECKPOINT,\n",
    "        rag_type=\"sequence\"\n",
    "    )\n",
    "\n",
    "    for k in K_VALUES:\n",
    "        print(f\"\\nProcessing k={k} for RAG-Sequence...\")\n",
    "        rag_seq_mgr.set_n_docs(k)\n",
    "\n",
    "        start_time = time.time()\n",
    "        predictions = rag_seq_mgr.generate_answers(questions, batch_size=BATCH_SIZE)\n",
    "        score = calculate_em(predictions, answers)\n",
    "\n",
    "        results[\"rag-sequence\"][\"scores\"].append(score)\n",
    "        with open(\"benchmark_wq_k_results.json\", \"w\") as f:\n",
    "            json.dump(results, f)\n",
    "        print(f\"WQ Score (k={k}): {score:.2f}% (Time: {time.time()-start_time:.1f}s)\")\n",
    "\n",
    "    del rag_seq_mgr\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipping Sequence Model (No path provided)\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffd70d01-2de8-47fc-b399-61cb5d3b61b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T18:30:57.185572Z",
     "start_time": "2026-01-28T18:30:57.091870Z"
    }
   },
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot RAG-Token\n",
    "if results[\"rag-token\"][\"scores\"]:\n",
    "    plt.plot(\n",
    "        results[\"rag-token\"][\"k\"], \n",
    "        results[\"rag-token\"][\"scores\"], \n",
    "        marker='o', \n",
    "        label='Fine-Tuned RAG-Token', \n",
    "        linestyle='-', \n",
    "        color='blue'\n",
    "    )\n",
    "\n",
    "# Plot RAG-Sequence\n",
    "if results[\"rag-sequence\"][\"scores\"]:\n",
    "    plt.plot(\n",
    "        results[\"rag-sequence\"][\"k\"], \n",
    "        results[\"rag-sequence\"][\"scores\"], \n",
    "        marker='s', \n",
    "        label='Fine-Tuned RAG-Sequence', \n",
    "        linestyle='--', \n",
    "        color='green'\n",
    "    )\n",
    "\n",
    "plt.title(f'RAG Performance on WebQuestions (Fine-Tuned) vs Retrieved Docs (k)\\n(Samples: 2032)')\n",
    "plt.xlabel('Number of Retrieved Documents (k)')\n",
    "plt.ylabel('Exact Match (EM) Score %')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xticks(K_VALUES)\n",
    "\n",
    "plt.savefig(\"wq_k_performance_finetuned.png\")\n",
    "print(\"Plot saved as 'wq_k_performance_finetuned.png'\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as 'wq_k_performance_finetuned.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6734856571bd1ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
